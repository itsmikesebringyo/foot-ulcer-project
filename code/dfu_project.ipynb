{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "dfu_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AT5AcJWte5u"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "id": "7AT5AcJWte5u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boolean-optimization"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "id": "boolean-optimization",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "special-headquarters"
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import VGG16\n",
        "import tensorflow.keras.backend as K"
      ],
      "id": "special-headquarters",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meaningful-apple"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "meaningful-apple",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjqaTNGXt5zt"
      },
      "source": [
        "tfds.__version__"
      ],
      "id": "IjqaTNGXt5zt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0VrCgtV7wby"
      },
      "source": [
        "!pip install tensorflow-datasets==4.3.0"
      ],
      "id": "b0VrCgtV7wby",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "distinguished-healing"
      },
      "source": [
        "dataset, info = tfds.load('foot_ulcer:1.2.0', data_dir='gs://foot_ulcer', with_info=True)"
      ],
      "id": "distinguished-healing",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trying-teaching"
      },
      "source": [
        "info"
      ],
      "id": "trying-teaching",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "incident-effort"
      },
      "source": [
        "example = dataset['train'].take(1)\n",
        "for sample in example:\n",
        "    image, mask = sample[\"image\"], sample[\"segmentation_mask\"]\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(tf.keras.preprocessing.image.array_to_img(image))\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(tf.keras.preprocessing.image.array_to_img(mask))\n",
        "    plt.show()"
      ],
      "id": "incident-effort",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "forbidden-valve"
      },
      "source": [
        "def normalize(input_image, input_mask):\n",
        "  input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "  input_mask = tf.round(tf.cast(input_mask, tf.float32) / 255.0)\n",
        "  return input_image, input_mask"
      ],
      "id": "forbidden-valve",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thorough-strength"
      },
      "source": [
        "img_height = 128\n",
        "img_width = 128"
      ],
      "id": "thorough-strength",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "civilian-aerospace"
      },
      "source": [
        "@tf.function\n",
        "def load_image_train(datapoint):\n",
        "  input_image = tf.image.resize(datapoint['image'], (img_height, img_width))\n",
        "  input_mask = tf.image.resize(datapoint['segmentation_mask'], (img_height, img_width))\n",
        "\n",
        "  if tf.random.uniform(()) > 0.5:\n",
        "    input_image = tf.image.flip_left_right(input_image)\n",
        "    input_mask = tf.image.flip_left_right(input_mask)\n",
        "\n",
        "  input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "  return input_image, input_mask"
      ],
      "id": "civilian-aerospace",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "manual-victorian"
      },
      "source": [
        "def load_image_test(datapoint):\n",
        "  input_image = tf.image.resize(datapoint['image'], (img_height, img_width))\n",
        "  input_mask = tf.image.resize(datapoint['segmentation_mask'], (img_height, img_width))\n",
        "\n",
        "  input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "  return input_image, input_mask"
      ],
      "id": "manual-victorian",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rural-zealand"
      },
      "source": [
        "train = dataset['train'].map(load_image_train, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test = dataset['test'].map(load_image_test)"
      ],
      "id": "rural-zealand",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "antique-musical"
      },
      "source": [
        "example = train.take(1)\n",
        "for image, mask in example:\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(tf.keras.preprocessing.image.array_to_img(image))\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(tf.keras.preprocessing.image.array_to_img(mask))\n",
        "    plt.show()"
      ],
      "id": "antique-musical",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acoustic-queue"
      },
      "source": [
        "TRAIN_LENGTH = info.splits['train'].num_examples\n",
        "BATCH_SIZE = 16\n",
        "BUFFER_SIZE = 1000\n",
        "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE"
      ],
      "id": "acoustic-queue",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "found-opposition"
      },
      "source": [
        "train_dataset = train.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "test_dataset = test.batch(BATCH_SIZE)"
      ],
      "id": "found-opposition",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "starting-acoustic"
      },
      "source": [
        "def display(display_list):\n",
        "  plt.figure(figsize=(15, 15))\n",
        "\n",
        "  title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "  for i in range(len(display_list)):\n",
        "    plt.subplot(1, len(display_list), i+1)\n",
        "    plt.title(title[i])\n",
        "    plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ],
      "id": "starting-acoustic",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "transparent-louisiana"
      },
      "source": [
        "for image, mask in train.take(7):\n",
        "  sample_image, sample_mask = image, mask\n",
        "display([sample_image, sample_mask])"
      ],
      "id": "transparent-louisiana",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arranged-patrick"
      },
      "source": [
        "def conv_block(input_shape, num_filters):\n",
        "    \"\"\"build convolutional block for decoder portion\"\"\"\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(input_shape)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x"
      ],
      "id": "arranged-patrick",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "victorian-examination"
      },
      "source": [
        "def decoder_block(input_shape, skip_features, num_filters):\n",
        "    \"\"\"build decoder block\"\"\"\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input_shape)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x"
      ],
      "id": "victorian-examination",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "visible-edmonton"
      },
      "source": [
        "def vgg16_unet(input_shape):\n",
        "    \"create input layer\"\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    \"get base vgg16 model\"\n",
        "    vgg16 = VGG16(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
        "\n",
        "    \"create encoder section\"\n",
        "    s1 = vgg16.get_layer(\"block1_conv2\").output\n",
        "    s2 = vgg16.get_layer(\"block2_conv2\").output\n",
        "    s3 = vgg16.get_layer(\"block3_conv3\").output\n",
        "    s4 = vgg16.get_layer(\"block4_conv3\").output\n",
        "\n",
        "    \"create bridge section\"\n",
        "    b1 = vgg16.get_layer(\"block5_conv3\").output\n",
        "\n",
        "    \"create decoder section\"\n",
        "    d1 = decoder_block(b1, s4, 512)\n",
        "    d2 = decoder_block(d1, s3, 256)\n",
        "    d3 = decoder_block(d2, s2, 128)\n",
        "    d4 = decoder_block(d3, s1, 64)\n",
        "\n",
        "    \"create output layer\"\n",
        "    outputs = Conv2D(2, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model"
      ],
      "id": "visible-edmonton",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "right-capital"
      },
      "source": [
        "model = vgg16_unet(sample_image.shape)"
      ],
      "id": "right-capital",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS1usXMkR7kT"
      },
      "source": [
        "# define custom metric function for DICE coefficient\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    y_pred = tf.argmax(y_pred, axis=-1)\n",
        "    y_true = tf.reshape(y_true, (img_height, img_width, 1))\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.cast(K.flatten(y_pred), 'float32')\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    dice = (2. * K.sum(intersection) + smooth) / ((K.sum(y_true_f) + K.sum(y_pred_f)) + smooth)\n",
        "    return dice"
      ],
      "id": "bS1usXMkR7kT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "impressive-enlargement"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy', dice_coef])"
      ],
      "id": "impressive-enlargement",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "cognitive-feelings"
      },
      "source": [
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "id": "cognitive-feelings",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shaped-coordination"
      },
      "source": [
        "def create_mask(pred_mask):\n",
        "  pred_mask = tf.argmax(pred_mask, axis=-1)\n",
        "  pred_mask = pred_mask[..., tf.newaxis]\n",
        "  return pred_mask[0]"
      ],
      "id": "shaped-coordination",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "framed-asian"
      },
      "source": [
        "def show_predictions(dataset=None, num=1):\n",
        "  if dataset:\n",
        "    for image, mask in dataset.take(num):\n",
        "      pred_mask = model.predict(image)\n",
        "      display([image[0], mask[0], create_mask(pred_mask)])\n",
        "  else:\n",
        "    display([sample_image, sample_mask,\n",
        "             create_mask(model.predict(sample_image[tf.newaxis, ...]))])"
      ],
      "id": "framed-asian",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sonic-sphere"
      },
      "source": [
        "show_predictions()"
      ],
      "id": "sonic-sphere",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apparent-trace"
      },
      "source": [
        "class DisplayCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    clear_output(wait=True)\n",
        "    show_predictions()\n",
        "    print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"
      ],
      "id": "apparent-trace",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "civic-memphis"
      },
      "source": [
        "EPOCHS = 50\n",
        "VAL_SUBSPLITS = 5\n",
        "VALIDATION_STEPS = info.splits['test'].num_examples//BATCH_SIZE//VAL_SUBSPLITS\n",
        "\n",
        "model_history = model.fit(train_dataset, epochs=EPOCHS,\n",
        "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                          validation_steps=VALIDATION_STEPS,\n",
        "                          validation_data=test_dataset,\n",
        "                          callbacks=[DisplayCallback()])"
      ],
      "id": "civic-memphis",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd4DUAjUTw4G"
      },
      "source": [
        "model_history.history['val_accuracy'][-1]"
      ],
      "id": "hd4DUAjUTw4G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OJG3HWsR62e"
      },
      "source": [
        "model_history.history['val_dice_coef'][-1]"
      ],
      "id": "_OJG3HWsR62e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpv4LgNtY3Ov"
      },
      "source": [
        "model.summary()"
      ],
      "id": "tpv4LgNtY3Ov",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bOAw9gLgQFS"
      },
      "source": [
        "len(model.layers)"
      ],
      "id": "6bOAw9gLgQFS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XomZKrPEhIa9"
      },
      "source": [
        ""
      ],
      "id": "XomZKrPEhIa9",
      "execution_count": null,
      "outputs": []
    }
  ]
}